{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ce05971",
   "metadata": {},
   "source": [
    "1. Tools for text processing\n",
    "\n",
    "What are the most frequent words in Herman Melville's novel, Moby Dick, and how often do they occur?\n",
    "\n",
    "In this notebook, we'll scrape the novel Moby Dick from the website Project Gutenberg (which contains a large corpus of books) using the Python package requests. Then we'll extract words from this web data using BeautifulSoup. Finally, we'll dive into analyzing the distribution of words using the Natural Language ToolKit (nltk) and Counter.\n",
    "\n",
    "The Data Science pipeline we'll build in this notebook can be used to visualize the word frequency distributions of any novel that you can find on Project Gutenberg. The natural language processing tools used here apply to much of the data that data scientists encounter as a vast proportion of the world's data is unstructured data and includes a great deal of text.\n",
    "\n",
    "Let's start by loading in the three main Python packages we are going to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8495072c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing requests, BeautifulSoup, nltk, and Counter\n",
    "# ... YOUR CODE FOR TASK 1 ...\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1392da3b",
   "metadata": {},
   "source": [
    "2. Request Moby Dick\n",
    "To analyze Moby Dick, we need to get the contents of Moby Dick from somewhere. Luckily, the text is freely available online at Project Gutenberg as an HTML file: https://www.gutenberg.org/files/2701/2701-h/2701-h.htm .\n",
    "\n",
    "Note that HTML stands for Hypertext Markup Language and is the standard markup language for the web.\n",
    "\n",
    "To fetch the HTML file with Moby Dick we're going to use the request package to make a GET request for the website, which means we're getting data from it. This is what you're doing through a browser when visiting a webpage, but now we're getting the requested page directly into Python instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6837964",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
